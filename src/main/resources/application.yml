server:
  port: 8080
  servlet:
    context-path: "/spring-ai"

spring:
  mvc:
    hiddenmethod:
      filter:
        enabled: true
  servlet:
    multipart:
      max-file-size: "20MB"
      max-request-size: "20MB"
  application:
    name: "spring-ai"
  threads:
    virtual:
      enabled: true
  ai:
    model:
      chat: "${APP_AI_CHAT_PROVIDER:ollama}"
    chat:
      client:
        enabled: false
    openai:
      api-key: ${OPEN_AI_KEY}
      base-url: ${OPEN_AI_BASE_URL:https://api.openai.com}
      chat:
        completions-path: "/v1/chat/completions"
        options:
          model: ${OPEN_AI_CHAT_MODEL:gpt-4o}
    bedrock:
      aws:
        region: "${AI_BEDROCK_AWS_REGION:us-east-1}"
        access-key: "${AWS_AI_ACCESS_KEY_ID}"
        secret-key: "${AWS_AI_SECRET_ACCESS_KEY}"
        timeout: "10m"
      converse:
        chat:
          options:
            model: "${AI_BEDROCK_CHAT_MODEL:amazon.nova-pro-v1:0}"
      cohere:
        embedding:
          enabled: "${AI_BEDROCK_EMBEDDING_ENABLED:false}"
          model: "${AI_BEDROCK_EMBEDDING_MODEL:cohere.embed-multilingual-v3}"
    ollama:
      base-url: "${AI_OLLAMA_BASE_URL:http://localhost:11434}"
    vectorstore:
      pgvector:
        schema-name: "public"
        table-name: "rag_vector_store"
        index-type: "${AI_VECTOR_INDEX_TYPE:HNSW}"
        dimensions: "${AI_EMBEDDING_DIMENSIONS:1024}"
        distance-type: COSINE_DISTANCE
        batching-strategy: TOKEN_COUNT # Optional: Controls how documents are batched for embedding
        max-document-batch-size: 10000 # Optional: Maximum number of documents per batch
        schema-validation: true
  flyway:
    enabled: ${AI_CREATE_PG_VECTOR_DATABASE:true}
    placeholders:
      embeddingDimensions: ${spring.ai.vectorstore.pgvector.dimensions}
      vectorIndexType: ${spring.ai.vectorstore.pgvector.index-type}
  datasource:
    hikari:
      jdbc-url: "${DATASOURCE_URL:jdbc:postgresql://localhost:5432/mydatabase}"
      username: "${DATASOURCE_USERNAME:myuser}"
      password: "${DATASOURCE_PASSWORD:secret}"
      maximum-pool-size: 30
      driver:
        class:
          name: org.postgresql.Driver
app:
  ai:
    chat_history:
      table_name: "chat_history_vector_store"
    secure_rag:
      table_name: "secure_rag_vector_store"
    chat:
      provider: "${APP_AI_CHAT_PROVIDER:ollama}"
      model: "${APP_AI_CHAT_MODEL:llama3.2:3b}"
    translator:
      provider: "${APP_AI_TRANSLATOR_PROVIDER:ollama}"
      model: "${APP_AI_TRANSLATOR_MODEL:zongwei/gemma3-translator:4b}"
      chunk-size: "${APP_AI_TRANSLATOR_CHUNK_SIZE:150}"
    embedding:
      provider: "${APP_AI_EMBEDDING_PROVIDER:ollama}"
      model: "${APP_AI_EMBEDDING_MODEL:mxbai-embed-large}"
    image-extraction:
      provider: "${APP_AI_IMAGE_EXTRACTION_PROVIDER:ollama}"
      model: "${APP_AI_IMAGE_EXTRACTION_MODEL:llava:7b}"

vllm:
  chat:
    api-key: "${VLLM_CHAT_API_KEY:SAMPLE_SECRET_FROM_VAULT}"
    base-url: "${VLLM_CHAT_API_BASE_URL:http://localhost:8000}"
    timeout: "PT120S"
    completions-path: "/v1/chat/completions"
    model: "${VLLM_CHAT_MODEL:openai/gpt-oss-20b}"
  embedding:
    api-key: "${VLLM_EMBEDDING_API_KEY:SAMPLE_SECRET_FROM_VAULT}"
    base-url: "${VLLM_EMBEDDING_API_BASE_URL:http://localhost:8001}"
    timeout: "PT120S"
    completions-path: "/v1/chat/completions"
    model: "${VLLM_EMBEDDING_MODEL:mixedbread-ai/mxbai-embed-large-v1}"

logging:
  pattern:
    console: '%clr(%d{yyyy-MM-dd HH:mm:ss.SSS}){faint} %clr(%5p) %clr(${PID:- }){magenta} %clr(---){faint} %clr([%15.15t]){faint} %clr(%-40.40logger{39}){cyan} %clr(:){faint} %X{x_request_id:-no_request_id} %m %wEx %n'
  level:
    web: INFO
    org:
      springframework:
        boot:
          autoconfigure:
            security:
              servlet:
                UserDetailsServiceAutoConfiguration: OFF
        ai: INFO

logback-access:
  pattern: '%t{yyyy-MM-dd HH:mm:ss.SSS} ACCESS_LOG %D %B %s %i{x-forwarded-for} %reqAttribute{x_request_id} %m %U%q'

logback.access:
  enabled: "${ACCESS_LOG_ENABLED:true}"
  tee-filter:
    enabled: "${ACCESS_TEE_LOG_ENABLED:true}"